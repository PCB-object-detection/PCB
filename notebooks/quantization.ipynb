{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd37035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics onnx onnxruntime onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063b29d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: /content/drive/MyDrive/likelion/PCB\n",
      "WEIGHTS_DIR: /content/drive/MyDrive/likelion/PCB/weights\n",
      "Current working directory: /content/drive/MyDrive/likelion/PCB\n",
      "files: [PosixPath('/content/drive/MyDrive/likelion/PCB/weights/best_yolov11m_imgsz1280.pt')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path.cwd().parents[0]   # notebooks -> PCB\n",
    "WEIGHTS_DIR = BASE_DIR / \"weights\"\n",
    "os.chdir(BASE_DIR)\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"WEIGHTS_DIR:\", WEIGHTS_DIR)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(\"files:\", list(WEIGHTS_DIR.glob(\"*.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948bd703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.2 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "üí° ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
      "YOLO11m summary (fused): 125 layers, 20,034,658 parameters, 0 gradients, 67.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/likelion/PCB/weights/best_yolov11m_imgsz1280.pt' with input shape (1, 3, 1280, 1280) BCHW and output shape(s) (1, 10, 33600) (38.8 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxslim>=0.1.71'] not found, attempting AutoUpdate...\n",
      "Using Python 3.12.12 environment at: /usr\n",
      "Resolved 10 packages in 291ms\n",
      "Prepared 2 packages in 45ms\n",
      "Installed 2 packages in 4ms\n",
      " + colorama==0.4.6\n",
      " + onnxslim==0.1.82\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 0.5s\n",
      "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 20...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 3.4s, saved as '/content/drive/MyDrive/likelion/PCB/weights/best_yolov11m_imgsz1280.onnx' (77.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['tensorrt-cu12>7.0.0,!=10.1.0'] not found, attempting AutoUpdate...\n",
      "Using Python 3.12.12 environment at: /usr\n",
      "   Building tensorrt-cu12-libs==10.14.1.48.post1\n",
      "      Built tensorrt-cu12-libs==10.14.1.48.post1\n",
      "Resolved 5 packages in 53.43s\n",
      "   Building tensorrt-cu12==10.14.1.48.post1\n",
      "Downloading nvidia-cuda-runtime-cu12 (3.3MiB)\n",
      " Downloaded nvidia-cuda-runtime-cu12\n",
      "      Built tensorrt-cu12==10.14.1.48.post1\n",
      "Prepared 4 packages in 16.28s\n",
      "Uninstalled 1 package in 4ms\n",
      "Installed 4 packages in 2ms\n",
      " - nvidia-cuda-runtime-cu12==12.6.77\n",
      " + nvidia-cuda-runtime-cu12==12.9.79\n",
      " + tensorrt-cu12==10.14.1.48.post1\n",
      " + tensorrt-cu12-bindings==10.14.1.48.post1\n",
      " + tensorrt-cu12-libs==10.14.1.48.post1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 70.4s\n",
      "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.14.1.48.post1...\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 1280, 1280) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 10, 33600) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as /content/drive/MyDrive/likelion/PCB/weights/best_yolov11m_imgsz1280.engine\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ‚úÖ 417.9s, saved as '/content/drive/MyDrive/likelion/PCB/weights/best_yolov11m_imgsz1280.engine' (40.1 MB)\n",
      "\n",
      "Export complete (420.0s)\n",
      "Results saved to \u001b[1m/content/drive/MyDrive/likelion/PCB/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/content/drive/MyDrive/likelion/PCB/weights/best_yolov11m_imgsz1280.engine imgsz=1280 half \n",
      "Validate:        yolo val task=detect model=/content/drive/MyDrive/likelion/PCB/weights/best_yolov11m_imgsz1280.engine imgsz=1280 data=/content/drive/MyDrive/·ÑÜ·Ö•·Ü∫·Ñâ·Ö°_AICV_3·ÑÄ·Öµ/1·Ñé·Ö° ·Ñë·Ö≥·ÑÖ·Ö©·Ñå·Ö¶·Ü®·Ñê·Ö≥/Team6_PCB_Merge_Data-2/data.yaml half \n",
      "Visualize:       https://netron.app\n",
      "Quantized files:\n",
      " - best_yolov11m_imgsz1280.pt\n",
      " - best_yolov11m_imgsz1280.onnx\n",
      " - best_yolov11m_imgsz1280.engine\n"
     ]
    }
   ],
   "source": [
    "from src.inference.quantization import Quantizer, quantize_model\n",
    "\n",
    "WEIGHTS_PATH = WEIGHTS_DIR / \"best_yolov11m_imgsz1280.pt\"\n",
    "quantizer = Quantizer(weights_path=str(WEIGHTS_PATH))\n",
    "quantizer.export_fp16()\n",
    "\n",
    "print(\"Quantized files:\")\n",
    "for f in WEIGHTS_DIR.glob(\"*\"):\n",
    "    print(\" -\", f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cc045",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f03b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = BASE_DIR / \"dataset/roboflow/test/images\"\n",
    "MODEL_PT = WEIGHTS_DIR / \"best_yolov11m_imgsz1280.pt\"\n",
    "MODEL_ENGINE = WEIGHTS_DIR / \"best_yolov11m_imgsz1280.engine\"\n",
    "\n",
    "test_images = list(TEST_DIR.glob(\"*.jpg\")) + list(TEST_DIR.glob(\"*.png\"))\n",
    "print(f\"Found {len(test_images)} test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8183a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def load_image(img_path):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def evaluate_model(model, images, conf=0.25, imgsz=1280):\n",
    "    inference_times = []\n",
    "    ng_count = 0\n",
    "\n",
    "    for img_path in images:\n",
    "        img = load_image(img_path)\n",
    "\n",
    "        t0 = time.time()\n",
    "        results = model.predict(img, imgsz=imgsz, conf=conf, verbose=False)[0]\n",
    "        t1 = time.time()\n",
    "        inference_times.append(t1 - t0)\n",
    "\n",
    "        # NG ÌåêÏ†ï: boxÍ∞Ä ÌïòÎÇòÎùºÎèÑ ÏûàÏúºÎ©¥ NG\n",
    "        if len(results.boxes) > 0:\n",
    "            ng_count += 1\n",
    "\n",
    "    avg_time = np.mean(inference_times)\n",
    "    fps = 1.0 / avg_time if avg_time > 0 else 0\n",
    "    total_images = len(images)\n",
    "    ok_count = total_images - ng_count\n",
    "\n",
    "    return {\n",
    "        \"avg_inference_time\": avg_time,\n",
    "        \"FPS\": fps,\n",
    "        \"total_images\": total_images,\n",
    "        \"NG\": ng_count,\n",
    "        \"OK\": ok_count,\n",
    "        \"NG_rate\": ng_count / total_images * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏõêÎ≥∏ Î™®Îç∏ ÌèâÍ∞Ä\n",
    "print(\"Evaluating original model (.pt)...\")\n",
    "model_pt = YOLO(str(MODEL_PT))\n",
    "pt_stats = evaluate_model(model_pt, test_images)\n",
    "print(\"Original Model Results:\", pt_stats)\n",
    "\n",
    "# TensorRT FP16 Î™®Îç∏ ÌèâÍ∞Ä\n",
    "print(\"\\nEvaluating TensorRT FP16 model (.engine)...\")\n",
    "model_trt = YOLO(str(MODEL_ENGINE))  # ultralytics engine ÏûêÎèô Ïù∏Ïãù\n",
    "trt_stats = evaluate_model(model_trt, test_images)\n",
    "print(\"TensorRT FP16 Model Results:\", trt_stats)\n",
    "\n",
    "# ÎπÑÍµêÌëú Ï∂úÎ†•\n",
    "df_compare = pd.DataFrame([pt_stats, trt_stats], index=[\"Original PT\", \"TensorRT FP16\"])\n",
    "print(\"\\n===== Performance Comparison =====\")\n",
    "df_compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
